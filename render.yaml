# Render Blueprint: nttv_chatbot_ext
# Drop this file in the repo root and deploy via "New → Blueprint" on Render.

services:
  - type: web
    name: nttv-chatbot
    runtime: python
    pythonVersion: 3.11.11   # <-- keep
    region: oregon
    plan: free               # keep for now; upgrade later as needed
    autoDeploy: true

    envVars:
      # === LLM / Provider ===
      - key: OPENAI_BASE_URL
        value: https://openrouter.ai/api/v1
      - key: MODEL
        value: google/gemma-3n-e4b-it         # <— changed from the free model
      - key: OPENAI_API_KEY
        sync: false                           # keep (set in dashboard)
      - key: OPENROUTER_API_KEY
        sync: false                           # keep (alias; set in dashboard)

      # === Retrieval / Index ===
      - key: EMBED_MODEL_NAME
        value: sentence-transformers/all-MiniLM-L6-v2
      - key: INDEX_DIR
        value: /var/data/index
      - key: CONFIG_PATH
        value: /var/data/index/config.json
      - key: INDEX_PATH
        value: /var/data/index/faiss.index    # keep (ingest dual-writes faiss.index + index.faiss)
      - key: META_PATH
        value: /var/data/index/meta.pkl
      - key: RANK_FILE
        value: data/nttv rank requirements.txt

      # === Decoding / Behavior ===
      - key: TOP_K
        value: "8"                            # keep your current value here
      - key: MAX_TOKENS
        value: "512"
      - key: TEMPERATURE
        value: "0.0"
      - key: WEAK_THRESH
        value: "0.35"
      - key: STREAMLIT_BROWSER_GATHER_USAGE_STATS
        value: "false"                        # keep existing flag
      - key: STREAMLIT_BROWSER_GATHERUSAGESTATS
        value: "false"                        # <— correct Streamlit var (added)

      # === (Optional) Model cache on persistent disk — speeds up cold starts ===
      - key: TRANSFORMERS_CACHE
        value: /var/data/hf_cache
      - key: SENTENCE_TRANSFORMERS_HOME
        value: /var/data/st_cache

    buildCommand: |
      python -m pip install -U pip
      pip install -r requirements.txt
      # (Re)build FAISS index from /data into the mounted disk
      python ingest.py

    startCommand: >
      streamlit run app.py
      --server.port $PORT
      --server.address 0.0.0.0

    # Persistent disk so the FAISS index survives restarts/redeploys
    disk:
      name: index-disk
      mountPath: /var/data/index
      sizeGB: 1
